{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMUR6dC2ch7x7C86CrKo4yl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahinul22/machine-learning-pretrained-model-/blob/main/EfficientNetB0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDXu8p77Bv4M",
        "outputId": "f88d8943-d7a7-4731-efd5-6d8dd94560eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Select your dataset.zip file\n",
        "!unzip dataset.zip -d dataset/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m-GR6A9lCTo0",
        "outputId": "0267df26-4d90-49a5-95ce-342b38415158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd3d7aa6-9755-48ac-b513-751232cc1d24\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd3d7aa6-9755-48ac-b513-751232cc1d24\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset.zip to dataset.zip\n",
            "Archive:  dataset.zip\n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0365.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0366.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0367.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0370.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0372.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0373.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0374.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0375.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0376.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0377.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0378.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0379.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0380.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0381.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0382.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0383.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0384.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0385.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0386.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0388.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0389.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0390.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0392.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0393.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0395.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0396.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0397.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0398.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0399.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0400.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0401.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0402.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0403.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0404.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0405.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0406.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0700.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0701.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0702.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0703.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0100.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0101.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0104.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0105.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0106.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0107.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0108.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0109.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0110.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0111.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0112.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0113.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0114.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0115.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0116.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0117.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0118.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0119.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0121.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0292.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0295.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0296.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0299.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0300.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0301.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0302.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0303.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0304.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0305.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0306.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0307.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0323.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0324.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0325.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0329.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0332.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0333.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0337.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0391.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Brown spot/DSC_0394.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0293.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0308.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0309.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0310.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0312.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0313.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0314.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0315.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0316.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0317.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0318.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0319.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0320.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0321.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0322.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0327.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0328.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0330.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0331.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0335.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0336.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0338.JPG  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0339.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0500.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0501.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0502.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0503.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0504.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0505.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0506.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0507.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0508.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0509.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0510.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0511.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0512.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0513.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0514.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0515.jpg  \n",
            "  inflating: dataset/rice_leaf_diseases/Leaf smut/DSC_0516.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras opencv-python matplotlib scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am5T7DTRFCpf",
        "outputId": "74a672c1-ceab-498f-eaa4-68eb03a5422b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    \"/content/dataset/rice_leaf_diseases\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val_data = train_datagen.flow_from_directory(\n",
        "    \"/content/dataset/rice_leaf_diseases\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sB0HQA-FE6G",
        "outputId": "f90a716d-0c93-466c-aa04-8fbd7b2c04e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 96 images belonging to 3 classes.\n",
            "Found 24 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False  # Freeze pretrained layers\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(train_data.num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrZHfCgGGkHU",
        "outputId": "5702ec5e-cc79-425b-ae7b-5aeaa43016e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8lXxGyQIwiB",
        "outputId": "8ba5dd61-17e0-442f-c1e4-be6dfd65e3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 7s/step - accuracy: 0.3828 - loss: 1.1321 - val_accuracy: 0.3333 - val_loss: 1.1056\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887ms/step - accuracy: 0.2565 - loss: 1.1649 - val_accuracy: 0.3333 - val_loss: 1.1355\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849ms/step - accuracy: 0.2852 - loss: 1.1832 - val_accuracy: 0.3333 - val_loss: 1.1136\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.3451 - loss: 1.1304 - val_accuracy: 0.3333 - val_loss: 1.1182\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 843ms/step - accuracy: 0.2826 - loss: 1.1449 - val_accuracy: 0.3333 - val_loss: 1.1004\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 851ms/step - accuracy: 0.3073 - loss: 1.1354 - val_accuracy: 0.3333 - val_loss: 1.1077\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 895ms/step - accuracy: 0.4141 - loss: 1.0957 - val_accuracy: 0.3333 - val_loss: 1.1047\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 879ms/step - accuracy: 0.3177 - loss: 1.1071 - val_accuracy: 0.3333 - val_loss: 1.0995\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.3138 - loss: 1.1182 - val_accuracy: 0.3333 - val_loss: 1.1017\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 905ms/step - accuracy: 0.3659 - loss: 1.0892 - val_accuracy: 0.3333 - val_loss: 1.1015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/rice_disease_efficientnetb0.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugpWyh7PI5bq",
        "outputId": "29c79e93-28f2-4467-cb0c-6acc18ac6c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(\"/content/drive/MyDrive/rice_disease_efficientnetb0.h5\")\n",
        "\n",
        "\n",
        "# Assuming you want to test with an image from the unzipped dataset\n",
        "# Let's pick an example image path from the unzip output\n",
        "img_path = \"/content/dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0702.jpg\" # Example path, change if needed\n",
        "\n",
        "# Check if the file exists before attempting to load\n",
        "if not os.path.exists(img_path):\n",
        "    print(f\"Error: Image file not found at {img_path}\")\n",
        "else:\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)/255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = model.predict(img_array)\n",
        "    class_idx = np.argmax(pred)\n",
        "\n",
        "    # Get the class labels from the training data generator\n",
        "    # You need access to train_data.class_indices which was created in cell 2sB0HQA-FE6G\n",
        "    # Assuming train_data is available in the environment\n",
        "    if 'train_data' in globals():\n",
        "        disease = list(train_data.class_indices.keys())[class_idx]\n",
        "        print(\"Predicted Disease:\", disease)\n",
        "    else:\n",
        "        print(\"Error: train_data object not found. Cannot retrieve class labels.\")\n",
        "        print(\"Prediction probabilities:\", pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtMjifQmJPYf",
        "outputId": "e2bb21be-b83a-4563-e338-15c3ae040c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c6964a6cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "Predicted Disease: Brown spot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(\"/content/drive/MyDrive/rice_disease_efficientnetb0.h5\")\n",
        "\n",
        "\n",
        "# Assuming you want to test with an image from the unzipped dataset\n",
        "# Let's pick an example image path from the unzip output\n",
        "img_path = \"/content/dataset/rice_leaf_diseases/Bacterial leaf blight/DSC_0702.jpg\" # Example path, change if needed\n",
        "\n",
        "# Check if the file exists before attempting to load\n",
        "if not os.path.exists(img_path):\n",
        "    print(f\"Error: Image file not found at {img_path}\")\n",
        "else:\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)/255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = model.predict(img_array)\n",
        "    class_idx = np.argmax(pred)\n",
        "\n",
        "    # Get the class labels from the training data generator\n",
        "    # You need access to train_data.class_indices which was created in cell 2sB0HQA-FE6G\n",
        "    # Assuming train_data is available in the environment\n",
        "    if 'train_data' in globals():\n",
        "        disease = list(train_data.class_indices.keys())[class_idx]\n",
        "        print(\"Predicted Disease:\", disease)\n",
        "    else:\n",
        "        print(\"Error: train_data object not found. Cannot retrieve class labels.\")\n",
        "        print(\"Prediction probabilities:\", pred)"
      ],
      "metadata": {
        "id": "gontroclQ979",
        "outputId": "d83a2380-d2de-4669-e1e0-b1febe5511e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "Predicted Disease: Brown spot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f6a9023",
        "outputId": "32e49099-f897-4a5e-e335-2be152d00ae1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(\"/content/drive/MyDrive/rice_disease_efficientnetb0.h5\")\n",
        "\n",
        "# Specify the directory containing the images you want to test\n",
        "test_image_dir = \"/content/dataset/rice_leaf_diseases/Leaf smut\" # Change this to the directory you want to test\n",
        "\n",
        "# Get the class labels from the training data generator (assuming it's still in the environment)\n",
        "if 'train_data' in globals():\n",
        "    class_labels = list(train_data.class_indices.keys())\n",
        "else:\n",
        "    print(\"Error: train_data object not found. Cannot retrieve class labels.\")\n",
        "    class_labels = None # Or load labels from a saved file\n",
        "\n",
        "# Iterate through the images in the directory\n",
        "if os.path.exists(test_image_dir):\n",
        "    for filename in os.listdir(test_image_dir):\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\")): # Add other image extensions if needed\n",
        "            img_path = os.path.join(test_image_dir, filename)\n",
        "\n",
        "            try:\n",
        "                img = image.load_img(img_path, target_size=(224, 224))\n",
        "                img_array = image.img_to_array(img) / 255.0\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "                pred = model.predict(img_array)\n",
        "                class_idx = np.argmax(pred)\n",
        "\n",
        "                if class_labels:\n",
        "                    predicted_disease = class_labels[class_idx]\n",
        "                    print(f\"Image: {filename}, Predicted Disease: {predicted_disease}\")\n",
        "                else:\n",
        "                    print(f\"Image: {filename}, Prediction probabilities: {pred}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image {filename}: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Test image directory not found at {test_image_dir}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "Image: DSC_0328.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Image: DSC_0516.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0509.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Image: DSC_0514.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Image: DSC_0503.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Image: DSC_0512.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0336.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0506.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Image: DSC_0507.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0339.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Image: DSC_0510.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Image: DSC_0504.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Image: DSC_0508.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0319.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0322.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Image: DSC_0501.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Image: DSC_0330.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Image: DSC_0502.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Image: DSC_0315.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0515.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Image: DSC_0513.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Image: DSC_0511.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Image: DSC_0505.jpg, Predicted Disease: Brown spot\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Image: DSC_0500.jpg, Predicted Disease: Brown spot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Install libraries (Colab has most already, but this is safe)\n",
        "!pip install -q tensorflow matplotlib scikit-learn opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rufYLK1fNBFm",
        "outputId": "95a7e0ad-cf6e-4d54-af8d-13fc0fcfbd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 22 09:55:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0             30W /   70W |    2168MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random, math\n",
        "random.seed(42)\n",
        "\n",
        "# Path where class folders live (update if needed)\n",
        "DATA_ROOT = \"/content/dataset\"\n",
        "\n",
        "# Detect if already split\n",
        "if os.path.exists(os.path.join(DATA_ROOT, \"train\")) and os.path.exists(os.path.join(DATA_ROOT, \"val\")):\n",
        "    print(\"Found existing train/val folders. Skipping split.\")\n",
        "    TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
        "    VAL_DIR   = os.path.join(DATA_ROOT, \"val\")\n",
        "else:\n",
        "    print(\"No split found. Creating train/val split (80/20).\")\n",
        "    ALL_DIR = DATA_ROOT  # class folders are directly inside DATA_ROOT\n",
        "    SPLIT_DIR = \"/content/data_split\"\n",
        "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
        "    VAL_DIR   = os.path.join(SPLIT_DIR, \"val\")\n",
        "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "    os.makedirs(VAL_DIR, exist_ok=True)\n",
        "\n",
        "    # classes = subfolders\n",
        "    classes = [d for d in os.listdir(ALL_DIR) if os.path.isdir(os.path.join(ALL_DIR, d))]\n",
        "    print(\"Classes:\", classes)\n",
        "\n",
        "    for cls in classes:\n",
        "        src = os.path.join(ALL_DIR, cls)\n",
        "        files = [f for f in os.listdir(src) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"))]\n",
        "        random.shuffle(files)\n",
        "        n_total = len(files)\n",
        "        n_val = max(1, int(0.2 * n_total))  # 20% validation\n",
        "        val_files = files[:n_val]\n",
        "        train_files = files[n_val:]\n",
        "\n",
        "        # make class dirs\n",
        "        os.makedirs(os.path.join(TRAIN_DIR, cls), exist_ok=True)\n",
        "        os.makedirs(os.path.join(VAL_DIR, cls), exist_ok=True)\n",
        "\n",
        "        for f in train_files:\n",
        "            shutil.copy2(os.path.join(src, f), os.path.join(TRAIN_DIR, cls, f))\n",
        "        for f in val_files:\n",
        "            shutil.copy2(os.path.join(src, f), os.path.join(VAL_DIR, cls, f))\n",
        "\n",
        "    print(\"Split complete.\")\n",
        "    !find /content/data_split -maxdepth 2 -type d -print\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhHcYD0dNhnx",
        "outputId": "ba8d6278-d111-474e-a1f7-9ba797476ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No split found. Creating train/val split (80/20).\n",
            "Classes: ['rice_leaf_diseases']\n",
            "Split complete.\n",
            "/content/data_split\n",
            "/content/data_split/train\n",
            "/content/data_split/train/rice_leaf_diseases\n",
            "/content/data_split/val\n",
            "/content/data_split/val/rice_leaf_diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "# Augmentation & preprocessing (use preprocess_input for EfficientNet)\n",
        "train_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.08,\n",
        "    height_shift_range=0.08,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_data = train_gen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "val_data = val_gen.flow_from_directory(\n",
        "    VAL_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to fix imbalance\n",
        "y_train = train_data.classes  # array of class indices for each sample in train generator\n",
        "classes = np.unique(y_train)\n",
        "class_weights_arr = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "class_weights = {i: w for i, w in enumerate(class_weights_arr)}\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Save label mapping (so you can load it later at inference time)\n",
        "label_map = {cls_name: int(idx) for cls_name, idx in train_data.class_indices.items()}\n",
        "with open(\"/content/drive/MyDrive/class_indices.json\", \"w\") as f:\n",
        "    json.dump(label_map, f, indent=2)\n",
        "print(\"Saved label map to Drive.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "-IB-UAt1Nnpp",
        "outputId": "f11993fe-b592-4ffb-8313-80b2143be611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 1 classes.\n",
            "Found 0 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "arrays used as indices must be of integer (or boolean) type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-441678953.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m  \u001b[0;31m# array of class indices for each sample in train generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mclass_weights_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mrecip_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecip_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# user-defined dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/dataset | head -50\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pOrsZ2NOV8B",
        "outputId": "25f0e3b4-c601-4428-aa61-bf9de26c23cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset:\n",
            "rice_leaf_diseases\n",
            "\n",
            "/content/dataset/rice_leaf_diseases:\n",
            "Bacterial leaf blight\n",
            "Brown spot\n",
            "Leaf smut\n",
            "\n",
            "/content/dataset/rice_leaf_diseases/Bacterial leaf blight:\n",
            "DSC_0365.JPG\n",
            "DSC_0366.jpg\n",
            "DSC_0367.JPG\n",
            "DSC_0370.jpg\n",
            "DSC_0372.JPG\n",
            "DSC_0373.JPG\n",
            "DSC_0374.JPG\n",
            "DSC_0375.JPG\n",
            "DSC_0376.JPG\n",
            "DSC_0377.JPG\n",
            "DSC_0378.JPG\n",
            "DSC_0379.JPG\n",
            "DSC_0380.JPG\n",
            "DSC_0381.JPG\n",
            "DSC_0382.JPG\n",
            "DSC_0383.JPG\n",
            "DSC_0384.JPG\n",
            "DSC_0385.jpg\n",
            "DSC_0386.JPG\n",
            "DSC_0388.JPG\n",
            "DSC_0389.JPG\n",
            "DSC_0390.JPG\n",
            "DSC_0392.JPG\n",
            "DSC_0393.JPG\n",
            "DSC_0395.JPG\n",
            "DSC_0396.JPG\n",
            "DSC_0397.JPG\n",
            "DSC_0398.JPG\n",
            "DSC_0399.JPG\n",
            "DSC_0400.JPG\n",
            "DSC_0401.JPG\n",
            "DSC_0402.JPG\n",
            "DSC_0403.JPG\n",
            "DSC_0404.JPG\n",
            "DSC_0405.JPG\n",
            "DSC_0406.JPG\n",
            "DSC_0700.jpg\n",
            "DSC_0701.jpg\n",
            "DSC_0702.jpg\n",
            "DSC_0703.JPG\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# STEP 0: Setup\n",
        "# =========================================\n",
        "!nvidia-smi   # check GPU\n",
        "!pip install -q tensorflow matplotlib scikit-learn opencv-python\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================================\n",
        "# STEP 1: Data pipeline (using validation_split)\n",
        "# =========================================\n",
        "import tensorflow as tf\n",
        "import numpy as np, json\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "DATASET_DIR = \"/content/dataset/rice_leaf_diseases\"\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights (to fix imbalance)\n",
        "y_train = train_data.classes\n",
        "classes = np.unique(y_train)\n",
        "class_weights_arr = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "class_weights = {i: w for i, w in enumerate(class_weights_arr)}\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Save label mapping\n",
        "label_map = {cls: idx for cls, idx in train_data.class_indices.items()}\n",
        "with open(\"/content/drive/MyDrive/class_indices.json\", \"w\") as f:\n",
        "    json.dump(label_map, f, indent=2)\n",
        "print(\"Saved label map:\", label_map)\n",
        "\n",
        "# =========================================\n",
        "# STEP 2: Build EfficientNet-B0 Model\n",
        "# =========================================\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base.trainable = False   # freeze for stage 1\n",
        "\n",
        "inputs = layers.Input(shape=(224,224,3))\n",
        "x = base(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(train_data.num_classes, activation=\"softmax\")(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(1e-3),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# =========================================\n",
        "# STEP 3: Train (Stage 1)\n",
        "# =========================================\n",
        "ckpt_stage1 = \"/content/drive/MyDrive/rice_efficientnetb0_stage1.keras\"\n",
        "cbs = [\n",
        "    EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(ckpt_stage1, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history1 = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=15,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=cbs\n",
        ")\n",
        "\n",
        "# Save stage 1 model\n",
        "model.save(\"/content/drive/MyDrive/rice_disease_efficientnetb0_stage1.keras\")\n",
        "\n",
        "# =========================================\n",
        "# STEP 4: Fine-tune (unfreeze top layers)\n",
        "# =========================================\n",
        "for layer in base.layers[-40:]:   # unfreeze last 40 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(5e-5),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "ckpt_final = \"/content/drive/MyDrive/rice_efficientnetb0_final.keras\"\n",
        "cbs_ft = [\n",
        "    EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(ckpt_final, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history2 = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=cbs_ft\n",
        ")\n",
        "\n",
        "# Save final model\n",
        "model.save(\"/content/drive/MyDrive/rice_disease_efficientnetb0_final.keras\")\n",
        "\n",
        "# =========================================\n",
        "# STEP 5: Evaluate\n",
        "# =========================================\n",
        "val_loss, val_acc = model.evaluate(val_data, verbose=0)\n",
        "print(f\"Final Validation Accuracy: {val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uTN2QPirOrxj",
        "outputId": "83445f1b-4246-48b9-cfca-e9afd707f801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 22 10:02:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0             30W /   70W |    2168MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 96 images belonging to 3 classes.\n",
            "Found 24 images belonging to 3 classes.\n",
            "Class weights: {0: np.float64(1.0), 1: np.float64(1.0), 2: np.float64(1.0)}\n",
            "Saved label map: {'Bacterial leaf blight': 0, 'Brown spot': 1, 'Leaf smut': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_41\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_41\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m3,843\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,053,414\u001b[0m (15.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,053,414</span> (15.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,843\u001b[0m (15.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> (15.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3976 - loss: 1.1849\n",
            "Epoch 1: val_accuracy improved from -inf to 0.79167, saving model to /content/drive/MyDrive/rice_efficientnetb0_stage1.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4s/step - accuracy: 0.4049 - loss: 1.1740 - val_accuracy: 0.7917 - val_loss: 0.7704 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.4983 - loss: 1.0330\n",
            "Epoch 2: val_accuracy improved from 0.79167 to 0.91667, saving model to /content/drive/MyDrive/rice_efficientnetb0_stage1.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 855ms/step - accuracy: 0.5091 - loss: 1.0215 - val_accuracy: 0.9167 - val_loss: 0.7041 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.6753 - loss: 0.8687\n",
            "Epoch 3: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - accuracy: 0.6810 - loss: 0.8569 - val_accuracy: 0.9167 - val_loss: 0.6372 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.8264 - loss: 0.7207\n",
            "Epoch 4: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495ms/step - accuracy: 0.8255 - loss: 0.7257 - val_accuracy: 0.9167 - val_loss: 0.5846 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.8212 - loss: 0.7196\n",
            "Epoch 5: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step - accuracy: 0.8216 - loss: 0.7095 - val_accuracy: 0.9167 - val_loss: 0.5386 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.7517 - loss: 0.6786\n",
            "Epoch 6: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - accuracy: 0.7721 - loss: 0.6628 - val_accuracy: 0.9167 - val_loss: 0.5040 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.8108 - loss: 0.6133\n",
            "Epoch 7: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - accuracy: 0.8216 - loss: 0.5958 - val_accuracy: 0.9167 - val_loss: 0.4794 - learning_rate: 0.0010\n",
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.5851 - loss: 0.9312\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87500, saving model to /content/drive/MyDrive/rice_efficientnetb0_final.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - accuracy: 0.5924 - loss: 0.9314 - val_accuracy: 0.8750 - val_loss: 0.6642 - learning_rate: 5.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.5538 - loss: 0.9725\n",
            "Epoch 2: val_accuracy did not improve from 0.87500\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 842ms/step - accuracy: 0.5612 - loss: 0.9692 - val_accuracy: 0.8750 - val_loss: 0.6321 - learning_rate: 5.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 0.6927 - loss: 0.8222\n",
            "Epoch 3: val_accuracy did not improve from 0.87500\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623ms/step - accuracy: 0.6992 - loss: 0.8201 - val_accuracy: 0.8750 - val_loss: 0.5984 - learning_rate: 5.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.7604 - loss: 0.7468\n",
            "Epoch 4: val_accuracy improved from 0.87500 to 0.91667, saving model to /content/drive/MyDrive/rice_efficientnetb0_final.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 883ms/step - accuracy: 0.7578 - loss: 0.7439 - val_accuracy: 0.9167 - val_loss: 0.5680 - learning_rate: 5.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.8316 - loss: 0.6422\n",
            "Epoch 5: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 512ms/step - accuracy: 0.8372 - loss: 0.6365 - val_accuracy: 0.9167 - val_loss: 0.5410 - learning_rate: 5.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.9253 - loss: 0.5765\n",
            "Epoch 6: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 540ms/step - accuracy: 0.9232 - loss: 0.5771 - val_accuracy: 0.9167 - val_loss: 0.5158 - learning_rate: 5.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.9306 - loss: 0.5368\n",
            "Epoch 7: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step - accuracy: 0.9271 - loss: 0.5377 - val_accuracy: 0.9167 - val_loss: 0.4941 - learning_rate: 5.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.8785 - loss: 0.4885\n",
            "Epoch 8: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - accuracy: 0.8802 - loss: 0.4886 - val_accuracy: 0.9167 - val_loss: 0.4747 - learning_rate: 5.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.9601 - loss: 0.4261\n",
            "Epoch 9: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782ms/step - accuracy: 0.9596 - loss: 0.4229 - val_accuracy: 0.9167 - val_loss: 0.4574 - learning_rate: 5.0000e-05\n",
            "Final Validation Accuracy: 91.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load final model + labels\n",
        "MODEL_PATH = \"/content/drive/MyDrive/rice_disease_efficientnetb0_final.keras\"\n",
        "LABELS_JSON = \"/content/drive/MyDrive/class_indices.json\"\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "with open(LABELS_JSON) as f:\n",
        "    label_map = json.load(f)\n",
        "index_to_class = {v:k for k,v in label_map.items()}\n",
        "print(\"Labels:\", index_to_class)\n",
        "\n",
        "# Test folder\n",
        "test_folder = \"/content/dataset/rice_leaf_diseases/Brown spot\"\n",
        "\n",
        "for fname in os.listdir(test_folder):\n",
        "    if fname.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "        path = os.path.join(test_folder, fname)\n",
        "        img = image.load_img(path, target_size=(224,224))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        probs = model.predict(x, verbose=0)[0]\n",
        "        idx = int(np.argmax(probs))\n",
        "        pred_class = index_to_class[idx]\n",
        "        print(f\"{fname:25s} → {pred_class:20s} ({probs[idx]:.3f}) | probs={np.round(probs,3)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJSJGPWyPmGc",
        "outputId": "e143503f-415a-4b58-b5bc-10cef9b61342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: {0: 'Bacterial leaf blight', 1: 'Brown spot', 2: 'Leaf smut'}\n",
            "DSC_0104.jpg              → Brown spot           (0.443) | probs=[0.246 0.443 0.311]\n",
            "DSC_0323.JPG              → Brown spot           (0.606) | probs=[0.26  0.606 0.134]\n",
            "DSC_0391.jpg              → Brown spot           (0.540) | probs=[0.342 0.54  0.118]\n",
            "DSC_0303.JPG              → Brown spot           (0.634) | probs=[0.218 0.634 0.148]\n",
            "DSC_0302.JPG              → Brown spot           (0.406) | probs=[0.34  0.406 0.255]\n",
            "DSC_0324.JPG              → Leaf smut            (0.408) | probs=[0.388 0.204 0.408]\n",
            "DSC_0112.jpg              → Brown spot           (0.583) | probs=[0.29  0.583 0.127]\n",
            "DSC_0119.jpg              → Brown spot           (0.656) | probs=[0.146 0.656 0.198]\n",
            "DSC_0121.jpg              → Brown spot           (0.613) | probs=[0.189 0.613 0.198]\n",
            "DSC_0111.jpg              → Brown spot           (0.639) | probs=[0.102 0.639 0.259]\n",
            "DSC_0307.JPG              → Brown spot           (0.434) | probs=[0.403 0.434 0.163]\n",
            "DSC_0109.jpg              → Brown spot           (0.680) | probs=[0.101 0.68  0.22 ]\n",
            "DSC_0300.JPG              → Brown spot           (0.617) | probs=[0.196 0.617 0.187]\n",
            "DSC_0110.jpg              → Brown spot           (0.777) | probs=[0.055 0.777 0.169]\n",
            "DSC_0333.JPG              → Brown spot           (0.689) | probs=[0.167 0.689 0.144]\n",
            "DSC_0114.jpg              → Brown spot           (0.757) | probs=[0.083 0.757 0.161]\n",
            "DSC_0306.JPG              → Bacterial leaf blight (0.458) | probs=[0.458 0.312 0.23 ]\n",
            "DSC_0394.jpg              → Brown spot           (0.604) | probs=[0.297 0.604 0.099]\n",
            "DSC_0117.jpg              → Brown spot           (0.700) | probs=[0.042 0.7   0.259]\n",
            "DSC_0113.jpg              → Brown spot           (0.533) | probs=[0.22  0.533 0.247]\n",
            "DSC_0337.JPG              → Bacterial leaf blight (0.473) | probs=[0.473 0.343 0.184]\n",
            "DSC_0329.jpg              → Bacterial leaf blight (0.362) | probs=[0.362 0.345 0.293]\n",
            "DSC_0107.jpg              → Brown spot           (0.805) | probs=[0.041 0.805 0.154]\n",
            "DSC_0332.JPG              → Brown spot           (0.521) | probs=[0.309 0.521 0.171]\n",
            "DSC_0305.JPG              → Brown spot           (0.574) | probs=[0.277 0.574 0.149]\n",
            "DSC_0296.jpg              → Brown spot           (0.503) | probs=[0.357 0.503 0.14 ]\n",
            "DSC_0101.jpg              → Brown spot           (0.709) | probs=[0.099 0.709 0.191]\n",
            "DSC_0100.jpg              → Brown spot           (0.669) | probs=[0.137 0.669 0.195]\n",
            "DSC_0304.JPG              → Brown spot           (0.591) | probs=[0.293 0.591 0.117]\n",
            "DSC_0301.JPG              → Brown spot           (0.546) | probs=[0.245 0.546 0.209]\n",
            "DSC_0292.JPG              → Brown spot           (0.762) | probs=[0.176 0.762 0.063]\n",
            "DSC_0325.JPG              → Bacterial leaf blight (0.441) | probs=[0.441 0.365 0.194]\n",
            "DSC_0116.jpg              → Brown spot           (0.725) | probs=[0.055 0.725 0.22 ]\n",
            "DSC_0106.jpg              → Brown spot           (0.626) | probs=[0.079 0.626 0.295]\n",
            "DSC_0115.jpg              → Brown spot           (0.846) | probs=[0.049 0.846 0.105]\n",
            "DSC_0105.jpg              → Brown spot           (0.688) | probs=[0.142 0.688 0.17 ]\n",
            "DSC_0118.jpg              → Brown spot           (0.643) | probs=[0.097 0.643 0.26 ]\n",
            "DSC_0295.JPG              → Brown spot           (0.643) | probs=[0.264 0.643 0.092]\n",
            "DSC_0299.JPG              → Brown spot           (0.598) | probs=[0.247 0.598 0.155]\n",
            "DSC_0108.jpg              → Brown spot           (0.651) | probs=[0.083 0.651 0.265]\n"
          ]
        }
      ]
    }
  ]
}